{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mtech/2020/satyaki_ghosh/codes/vulnerability_camera'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17225323618674102400\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 13318138779677625961\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 17395469517\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4454734710479415636\n",
      "physical_device_desc: \"device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:37:00.0, compute capability: 7.0\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 14788324112341259355\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# SET WHICH GPU TO USE\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "# import notebook_util\n",
    "# notebook_util.pick_gpu_lowest_memory()\n",
    "# import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAMERA-MODEL IDENTIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DENSENET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import Callback,ModelCheckpoint,LearningRateScheduler\n",
    "import pickle\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys \n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"/home/mtech/2020/satyaki_ghosh/codes/vulnerability_camera/DenseNet\"))\n",
    "import densenet\n",
    "\n",
    "\n",
    "\n",
    "IMG_SIZE = 224\n",
    "channels = 3\n",
    "image_dim = (IMG_SIZE, IMG_SIZE, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "# LOADING THE DATSET\n",
    "with open('/home/mtech/2020/satyaki_ghosh/codes/fastAdvTraining/fast_adversarial/CIFAR10/training_data.npy','rb') as f:\n",
    "    dummy = np.load(f, allow_pickle=True)\n",
    "dataset = list(dummy)\n",
    "\n",
    "# TRAIN-TEST SPLIT AND SHUFFLE THE PATCHES : (train,val,test) = (0.8,0.1,0.1)\n",
    "random.shuffle(dataset)\n",
    "split_ratio = 0.8\n",
    "split_num = int(len(dataset) * split_ratio)\n",
    "print(type(split_num))\n",
    "print(split_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING INPUT AND LABELS\n",
    "X = []\n",
    "for features,_ in dataset :\n",
    "  X.append(features)\n",
    "\n",
    "X = np.array(X).reshape(-1,IMG_SIZE,IMG_SIZE,channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEAN AND STD REQUIRED FOR FAST ADVERSARIAL TRAINING\n",
    "X.mean(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# CREATING TRAINING DATA\n",
    "training_data = dataset[0:split_num]\n",
    "\n",
    "# CREATING INPUT AND LABELS\n",
    "X = []\n",
    "Y = []\n",
    "for features,label in training_data :\n",
    "  X.append(features)\n",
    "  Y.append(label)\n",
    "    \n",
    "    \n",
    "# PREPROCESSING\n",
    "print(X[0].shape)\n",
    "X = np.array(X).reshape(-1,IMG_SIZE,IMG_SIZE,channels)\n",
    "X = X/255.0\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 224, 224, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4], dtype=object),\n",
       " array([15000, 15000, 15000, 15000, 15000]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = dummy[:,1]\n",
    "np.unique(labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data shape: (15000, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# CREATING TESTING DATA\n",
    "testing_data = dataset[split_num:]\n",
    "X_test = []\n",
    "Y_test = []\n",
    "for features,label in testing_data :\n",
    "  X_test.append(features)\n",
    "  Y_test.append(label)\n",
    "\n",
    "# PREPROCESSING\n",
    "X_test = np.array(X_test).reshape(-1,IMG_SIZE,IMG_SIZE,channels)\n",
    "X_test = X_test/255.0\n",
    "Y_test = np.array(Y_test)\n",
    "print(f'Test Data shape: {np.shape(X_test)}')\n",
    "\n",
    "# print(f'Checkpoint models: {os.listdir(checkpoint_dir)}')\n",
    "# latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "# print(f'Latest model : {latest}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f4f804000d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "#model = load_model(\"allchannel_patches100_classes5_patchsize224.h5\")\n",
    "\n",
    "# THIS GIVES 121 LAYERS INPITE OF MENTIONING 40\n",
    "# model = densenet.DenseNet(input_shape=image_dim, depth=40, nb_dense_block=4, growth_rate=32, nb_filter=64,\n",
    "#                     nb_layers_per_block=[6, 12, 24, 16], bottleneck=True, reduction=0.5,\n",
    "#                     dropout_rate=0.0, weight_decay=1e-4, subsample_initial_block=True,\n",
    "#                     include_top=False, weights=None, input_tensor=None,\n",
    "#                     classes=5)\n",
    "# model = densenet.DenseNet(classes=5, input_shape=image_dim, depth=121, growth_rate=12, \n",
    "#                     bottleneck=True, reduction=0.5)   \n",
    "\n",
    "model = densenet.DenseNet(input_shape=image_dim, depth=121, nb_dense_block=4, growth_rate=32, nb_filter=64,\n",
    "                    nb_layers_per_block=[6, 12, 24, 16], bottleneck=True, reduction=0.5,\n",
    "                    dropout_rate=0.0, weight_decay=1e-4, subsample_initial_block=True,\n",
    "                    include_top=True, input_tensor=None,   # weights=None,\n",
    "                    classes=5)\n",
    "opt = tf.keras.optimizers.SGD(learning_rate = 0.001, momentum = 0.9, decay = 0.0005)\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = opt , metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]) \n",
    "model.load_weights('training_1/cp_0069.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/1 - 48s - loss: 1.7291 - sparse_categorical_accuracy: 0.9423\n",
      "Accuracy: 94.23%\n",
      "Y_test label distrib: (array([0, 1, 2, 3, 4]), array([3010, 3010, 2991, 3020, 2969]))\n",
      "Y_pred_label distrib: (array([0, 1, 2, 3, 4]), array([3009, 3083, 3057, 2961, 2890]))\n",
      "Number of different predicted labels: (2, 5)\n",
      "Accuracy: 0.9423333333333334\n",
      "Confusion matrix: \n",
      "[[2971   17   12    4    6]\n",
      " [  14 2741   11   12  232]\n",
      " [   5   17 2913   34   22]\n",
      " [   7   30   87 2888    8]\n",
      " [  12  278   34   23 2622]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3010\n",
      "           1       0.89      0.91      0.90      3010\n",
      "           2       0.95      0.97      0.96      2991\n",
      "           3       0.98      0.96      0.97      3020\n",
      "           4       0.91      0.88      0.90      2969\n",
      "\n",
      "    accuracy                           0.94     15000\n",
      "   macro avg       0.94      0.94      0.94     15000\n",
      "weighted avg       0.94      0.94      0.94     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model():    \n",
    "    # # Create a new model instance\n",
    "    # model = create_model()\n",
    "\n",
    "    # # Load the previously saved weights\n",
    "    # model.load_weights(latest)\n",
    "\n",
    "    # Re-evaluate the model\n",
    "    loss, acc = model.evaluate(X_test, Y_test, verbose=2)\n",
    "    print(\"Accuracy: {:5.2f}%\".format(100 * acc))\n",
    "    Y_pred = model.predict(X_test)\n",
    "    Y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "    # Checking label distributions \n",
    "    #print(f'Y_train label distrib: {np.unique(Y, return_counts=True)}')\n",
    "    print(f'Y_test label distrib: {np.unique(Y_test, return_counts=True)}')\n",
    "    y_pred_distrib = np.unique(Y_pred, return_counts=True)\n",
    "    print(f'Y_pred_label distrib: {y_pred_distrib}')\n",
    "    #np.save('Y_pred_label_distrib_patchsize224.npy', y_pred_distrib)\n",
    "    print(f'Number of different predicted labels: {np.shape(np.unique(Y_pred, return_counts=True))}')\n",
    "\n",
    "\n",
    "    # Confusion Matrix\n",
    "    print(f\"Accuracy: {accuracy_score(Y_test, Y_pred)}\")\n",
    "    print(f\"Confusion matrix: \\n{confusion_matrix(Y_test, Y_pred)}\")\n",
    "    # np.save('confusion_matrix_patchsize224.npy', confusion_matrix(Y_test, Y_pred))\n",
    "    print(f\"Classification Report:\\n {classification_report(Y_test, Y_pred)}\")\n",
    "\n",
    "\n",
    "# try getting GPU until it is done\n",
    "ran = False\n",
    "while ran == False:\n",
    "    try:\n",
    "        evaluate_model()\n",
    "        ran = True\n",
    "    except:\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "413"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = np.load('train_history_dict.npy', allow_pickle=True).item()\n",
    "hist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist['loss'], label='loss')\n",
    "plt.plot(hist['val_loss'], label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist['sparse_categorical_accuracy'], label='sparse_categorical_accuracy')\n",
    "plt.plot(hist['val_sparse_categorical_accuracy'], label='val_sparse_categorical_accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred label_distrib = np.load('Y_pred label distrib.npy', allow_pickle=True)\n",
    "print(Y_pred label_distrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = np.load('confusion_matrix.npy', allow_pickle=True)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XCEPTIONNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cgi import test\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import Callback,ModelCheckpoint,LearningRateScheduler\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import pickle\n",
    "import math\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 3\n",
    "IMG_SIZE = 299\n",
    "DATADIR = \"/home/mtech/2020/satyaki_ghosh/datasets/VISION\"\n",
    "CATEGORIES = [\n",
    "    \"D01_Samsung_GalaxyS3Mini\",\n",
    "    \"D02_Apple_iPhone4s\",\n",
    "    \"D03_Huawei_P9\",\n",
    "    \"D04_LG_D290\",\n",
    "    \"D05_Apple_iPhone5c\"]\n",
    "patches_per_photo = 100\n",
    "img_per_model = 150\n",
    "num_classes = 5\n",
    "\n",
    "import sys \n",
    "import os\n",
    "\n",
    "\n",
    "image_dim = (IMG_SIZE, IMG_SIZE, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create generator\n",
    "datagen = ImageDataGenerator()\n",
    "# prepare an iterators for each dataset\n",
    "train_it = datagen.flow_from_directory('./xceptionNet/data/train/', class_mode='categorical', batch_size=32, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "val_it = datagen.flow_from_directory('./xceptionNet/data/val/', class_mode='categorical', batch_size=32, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "test_it = datagen.flow_from_directory('./xceptionNet/data/test/', class_mode='categorical', batch_size=32, target_size=(IMG_SIZE, IMG_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = tf.keras.applications.xception.Xception(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=image_dim,\n",
    "    pooling=None,\n",
    "    classes=5\n",
    "    #classifier_activation='softmax'\n",
    ")\n",
    "opt = tf.keras.optimizers.SGD(learning_rate = 0.001, momentum = 0.9, decay = 0.0005)\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = opt , metrics = [tf.keras.metrics.CategoricalAccuracy()])                \n",
    "\n",
    "# Save the weights using the `checkpoint_path` format\n",
    "model.load_weights('xceptionNet/training_1/cp_0051.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model():\n",
    "    loss, acc  = model.evaluate_generator(test_it)\n",
    "    print(\"Accuracy: {:5.2f}%\".format(100 * acc))\n",
    "\n",
    "\n",
    "    # Checking label distributions\n",
    "    Y_pred = model.predict_generator(test_it)\n",
    "    Y_pred = np.argmax(Y_pred, axis=1)\n",
    "    Y_test = test_it.classes\n",
    "    print(f'Y_train label distrib: {np.unique(Y, return_counts=True)}')\n",
    "    print(f'Y_test label distrib: {np.unique(Y_test, return_counts=True)}')\n",
    "    y_pred_distrib = np.unique(Y_pred, return_counts=True)\n",
    "    print(f'Y_pred_label distrib: {y_pred_distrib}')\n",
    "    print(f'Number of different predicted labels: {np.shape(np.unique(Y_pred, return_counts=True))}')\n",
    "\n",
    "\n",
    "    # Confusion Matrix\n",
    "    print(f\"Accuracy: {accuracy_score(Y_test, Y_pred)}\")\n",
    "    print(f\"Confusion matrix: \\n{confusion_matrix(Y_test, Y_pred)}\")\n",
    "    print(f\"Classification Report:\\n {classification_report(Y_test, Y_pred)}\")\n",
    "\n",
    "    \n",
    "# try getting GPU until it is done\n",
    "ran = False\n",
    "while ran == False:\n",
    "    try:\n",
    "        evaluate_model()\n",
    "        ran = True\n",
    "    except:\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shallowCNN (see under separate folder for shallowCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import Callback,ModelCheckpoint,LearningRateScheduler\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import math\n",
    "\n",
    "IMG_SIZE=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 3\n",
    "IMG_SIZE = 64\n",
    "DATADIR = \"/home/mtech/2020/satyaki_ghosh/datasets/VISION\"\n",
    "CATEGORIES = [\n",
    "    \"D01_Samsung_GalaxyS3Mini\",\n",
    "    \"D02_Apple_iPhone4s\",\n",
    "    \"D03_Huawei_P9\",\n",
    "    \"D04_LG_D290\",\n",
    "    \"D05_Apple_iPhone5c\"]\n",
    "patches_per_photo = 100\n",
    "img_per_model = 150\n",
    "num_classes = 5 \n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 80\n",
    "image_dim = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "\n",
    "# create generator\n",
    "datagen = ImageDataGenerator(\n",
    "                # featurewise_center=True,\n",
    "                samplewise_center=True,\n",
    "                rescale=0.0125\n",
    "            )\n",
    "# prepare an iterators for each dataset\n",
    "train_it = datagen.flow_from_directory('./data/train/', class_mode='categorical', batch_size=32, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "val_it = datagen.flow_from_directory('./data/val/', class_mode='categorical', batch_size=32, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "test_it = datagen.flow_from_directory('./data/test/', class_mode='categorical', batch_size=32, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "# confirm the iterator works\n",
    "batchX, batchy = train_it.next()\n",
    "print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))\n",
    "print(batchy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# layer 1 \n",
    "model.add(Conv2D(32, (4, 4), padding='valid', strides=(1,1), input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2,2)))\n",
    "# layer 2\n",
    "model.add(Conv2D(48, (5, 5), padding='valid', strides=(1,1)))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2,2)))\n",
    "# layer 3\n",
    "model.add(Conv2D(64, (5, 5), padding='same', strides=(1,1)))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2,2)))\n",
    "# # layer 4\n",
    "model.add(Conv2D(128, (5, 5), strides=(1,1)))\n",
    "# layer 5\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
