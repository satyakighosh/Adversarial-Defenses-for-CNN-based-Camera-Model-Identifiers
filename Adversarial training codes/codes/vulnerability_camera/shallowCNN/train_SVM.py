import pickle
import numpy as np
import os
import math
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, AveragePooling2D
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.callbacks import Callback,ModelCheckpoint,LearningRateScheduler
from keras.backend.tensorflow_backend import set_session
from keras.preprocessing.image import ImageDataGenerator
from sklearn import svm
import sklearn.model_selection as model_selection


print(tf.test.is_gpu_available(cuda_only=True))
config = tf.compat.v1.ConfigProto()
config.gpu_options.allow_growth = True    
config.gpu_options.per_process_gpu_memory_fraction = 0.6  # 0.6 sometimes works better for folks
sess =  tf.compat.v1.InteractiveSession(config=config)
set_session(sess)
os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'

# gpu_options = tf.compat.v1.GPUOptions(allow_growth=True, per_process_gpu_memory_fraction=0.8)
# config = tf.compat.v1.ConfigProto(
#     device_count={'GPU': 10, 'CPU': 10},
#     gpu_options=gpu_options,
#     intra_op_parallelism_threads=32,
#     inter_op_parallelism_threads=32,
#     )
# config.gpu_options.allow_growth = True
# sess = tf.compat.v1.Session(config=config)
# tf.compat.v1.keras.backend.set_session(sess)



channels = 3
IMG_SIZE = 64
DATADIR = "/home/mtech/2020/satyaki_ghosh/datasets/VISION"
CATEGORIES = [
    "D01_Samsung_GalaxyS3Mini",
    "D02_Apple_iPhone4s",
    "D03_Huawei_P9",
    "D04_LG_D290",
    "D05_Apple_iPhone5c"]
patches_per_photo = 100
img_per_model = 150
num_classes = 5
batch_size = 128
epochs = 80
image_dim = (IMG_SIZE, IMG_SIZE, 3)




# create generator
datagen = ImageDataGenerator(
                # featurewise_center=True,
                samplewise_center=True,
                rescale=0.0125
            )
# prepare an iterators for each dataset
train_it = datagen.flow_from_directory('./data/train/', class_mode='categorical', batch_size=25000, target_size=(IMG_SIZE, IMG_SIZE))
val_it = datagen.flow_from_directory('./data/val/', class_mode='categorical', batch_size=32, target_size=(IMG_SIZE, IMG_SIZE))
test_it = datagen.flow_from_directory('./data/test/', class_mode='categorical', batch_size=32, target_size=(IMG_SIZE, IMG_SIZE))



# define the model
model = Sequential()
# layer 1 
model.add(Conv2D(32, (4, 4), padding='valid', strides=(1,1), input_shape=(IMG_SIZE, IMG_SIZE, 3)))
model.add(MaxPooling2D((2, 2), strides=(2,2)))
# layer 2
model.add(Conv2D(48, (5, 5), padding='valid', strides=(1,1)))
model.add(MaxPooling2D((2, 2), strides=(2,2)))
# layer 3
model.add(Conv2D(64, (5, 5), padding='same', strides=(1,1)))
model.add(MaxPooling2D((2, 2), strides=(2,2)))
# # layer 4
model.add(Conv2D(128, (5, 5), strides=(1,1)))
model.add(Flatten())
# layer 5
model.add(Dense(128, activation='relu'))
# layer 6
model.add(Dense(5, activation='softmax'))

opt = tf.keras.optimizers.SGD(learning_rate = 0.015, momentum = 0.9, decay = 0.0075)
model.compile(loss = "categorical_crossentropy", optimizer = opt , metrics = [tf.keras.metrics.CategoricalAccuracy()])                
model.summary()

model.load_weights('./training_1/cp_0080.ckpt')


# define the encoder
encoder = Sequential()
# layer 1 
encoder.add(Conv2D(32, (4, 4), padding='valid', strides=(1,1), input_shape=(IMG_SIZE, IMG_SIZE, 3)))
encoder.add(MaxPooling2D((2, 2), strides=(2,2)))
# layer 2
encoder.add(Conv2D(48, (5, 5), padding='valid', strides=(1,1)))
encoder.add(MaxPooling2D((2, 2), strides=(2,2)))
# layer 3
encoder.add(Conv2D(64, (5, 5), padding='same', strides=(1,1)))
encoder.add(MaxPooling2D((2, 2), strides=(2,2)))
# # layer 4
encoder.add(Conv2D(128, (5, 5), strides=(1,1)))
encoder.add(Flatten())
# layer 5
encoder.add(Dense(128, activation='relu'))
encoder.summary()


#set weights of the encoder
for i in range(len(encoder.layers)):
    encoder.layers[i].set_weights(model.layers[i].get_weights())

#compile it after setting the weights
opt = tf.keras.optimizers.SGD(learning_rate = 0.015, momentum = 0.9, decay = 0.0075)
encoder.compile(loss = "categorical_crossentropy", optimizer = opt , metrics = [tf.keras.metrics.CategoricalAccuracy()])

# ---------------------------------------------------------------------------------------------------------------------------

# SVM training


# keep hitting GPU till it's free
def evaluate_model():
    return encoder.predict_generator(train_it) 

# ran = False
# while ran == False:
#     try:
#         X_train = evaluate_model()
#         ran = True
#     except:
#         pass
X_train = evaluate_model()

y_train = train_it.classes

print('Starting SVM training')
linear_svm = svm.SVC(kernel='linear', decision_function_shape='ovo', C=1).fit(X_train, y_train)
# rbf = svm.SVC(kernel='rbf', gamma=0.5, C=0.1).fit(X_train, y_train) 
# poly = svm.SVC(kernel='poly', degree=3, C=1).fit(X_train, y_train)


# SVM testing
X_test = encoder.predict_generator(test_it)
y_test = test_it.classes
linear_pred = linear_svm.predict(X_test)
# poly_pred = poly.predict(X_test)
# rbf_pred = rbf.predict(X_test)


# metrics
linear_accuracy = accuracy_score(y_test, linear_pred)
linear_f1 = f1_score(y_test, linear_pred, average='weighted')
print('Accuracy (linear Kernel): ', "%.2f" % (linear_accuracy*100))
print('F1 (linear Kernel): ', "%.2f" % (linear_f1*100))
print(f"Confusion matrix: \n{confusion_matrix(y_test, linear_pred)}")
np.save('./confusion_matrix_linear_svm.npy', confusion_matrix(y_test, linear_pred))
print(f"Classification Report:\n {classification_report(y_test, linear_pred)}")

# save the model
pickle.dump(linear_svm, open('linear_OVO_svm.sav', 'wb'))
# load the model from disk
# loaded_model = pickle.load(open(filename, 'rb'))
# result = loaded_model.score(X_test, Y_test)
# print(result)


# poly_accuracy = accuracy_score(y_test, poly_pred)
# poly_f1 = f1_score(y_test, poly_pred, average='weighted')
# print('Accuracy (Polynomial Kernel): ', "%.2f" % (poly_accuracy*100))
# print('F1 (Polynomial Kernel): ', "%.2f" % (poly_f1*100))

# rbf_accuracy = accuracy_score(y_test, rbf_pred)
# rbf_f1 = f1_score(y_test, rbf_pred, average='weighted')
# print('Accuracy (RBF Kernel): ', "%.2f" % (rbf_accuracy*100))
# print('F1 (RBF Kernel): ', "%.2f" % (rbf_f1*100))

