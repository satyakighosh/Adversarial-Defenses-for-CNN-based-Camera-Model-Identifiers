import numpy as np
import os
import math
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, AveragePooling2D
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.callbacks import Callback,ModelCheckpoint,LearningRateScheduler
from keras.backend.tensorflow_backend import set_session
from keras.preprocessing.image import ImageDataGenerator
from sklearn import svm
import sklearn.model_selection as model_selection

#DYNAMICALLY GROW THE GPU MEMORY

# ORIGINAL_CODE:
# print(tf.test.is_gpu_available(cuda_only=True))
# config = tf.compat.v1.ConfigProto()
# config.gpu_options.allow_growth = True    
# config.gpu_options.per_process_gpu_memory_fraction = 0.6  # 0.6 sometimes works better for folks
# sess =  tf.compat.v1.InteractiveSession(config=config)
# set_session(sess)
# os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'

# MRINMOY'S CODE:
gpu_options = tf.compat.v1.GPUOptions(allow_growth=True, per_process_gpu_memory_fraction=0.8)
config = tf.compat.v1.ConfigProto(
    device_count={'GPU': 10, 'CPU': 10},
    gpu_options=gpu_options,
    intra_op_parallelism_threads=32,
    inter_op_parallelism_threads=32,
    )
config.gpu_options.allow_growth = True
sess = tf.compat.v1.Session(config=config)
tf.compat.v1.keras.backend.set_session(sess)


channels = 3
IMG_SIZE = 64
DATADIR = "/home/mtech/2020/satyaki_ghosh/datasets/VISION"
CATEGORIES = [
    "D01_Samsung_GalaxyS3Mini",
    "D02_Apple_iPhone4s",
    "D03_Huawei_P9",
    "D04_LG_D290",
    "D05_Apple_iPhone5c"]
patches_per_photo = 100
img_per_model = 150
num_classes = 5


# TO DECAY THE LEARNING RATE WITH INCREASING EPOCHS
def step_decay(epoch):
  initial_lrate = 0.015
  drop = 0.5
  epochs_drop = 10.0
  lrate = initial_lrate * math.pow(drop, math.floor((1 + epoch) / epochs_drop))
  return lrate

lrate = LearningRateScheduler(step_decay)

batch_size = 128
epochs = 80

# Include the epoch in the file name (uses `str.format`)
checkpoint_path = "./training_1/cp_{epoch:04d}.ckpt"
checkpoint_dir = os.path.dirname(checkpoint_path)
checkpoint_epoch_freq = 1


# Create a callback that saves the model's weights every 5 epochs
cp_callback = tf.keras.callbacks.ModelCheckpoint(
    filepath=checkpoint_path, 
    verbose=1, 
    save_weights_only=True,
    save_freq='epoch' # checkpoint_epoch_freq*batch_size
  )


image_dim = (IMG_SIZE, IMG_SIZE, 3)


# create generator
datagen = ImageDataGenerator(
                # featurewise_center=True,
                samplewise_center=True,
                # featurewise_std_normalization=True,
                rescale=0.0125
            )            
# data generator for mean
# mean_datagen = ImageDataGenerator()  
# mean_it = mean_datagen.flow_from_directory('./data/train/', class_mode='categorical', batch_size=50000, target_size=(IMG_SIZE, IMG_SIZE))
# meanX_batch, _ = mean_it.next()
# datagen.fit(meanX_batch)

# prepare an iterators for each dataset
train_it = datagen.flow_from_directory('./data/train/', class_mode='categorical', batch_size=batch_size, target_size=(IMG_SIZE, IMG_SIZE))
val_it = datagen.flow_from_directory('./data/val/', class_mode='categorical', batch_size=batch_size, target_size=(IMG_SIZE, IMG_SIZE))
test_it = datagen.flow_from_directory('./data/test/', class_mode='categorical', batch_size=batch_size, target_size=(IMG_SIZE, IMG_SIZE))
# confirm the iterator works
batchX, batchy = train_it.next()
print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))
print(batchy.shape)



# define the model
model = Sequential()
# layer 1 
model.add(Conv2D(32, (4, 4), padding='valid', strides=(1,1), input_shape=(IMG_SIZE, IMG_SIZE, 3)))
model.add(MaxPooling2D((2, 2), strides=(2,2)))
# layer 2
model.add(Conv2D(48, (5, 5), padding='valid', strides=(1,1)))
model.add(MaxPooling2D((2, 2), strides=(2,2)))
# layer 3
model.add(Conv2D(64, (5, 5), padding='same', strides=(1,1)))
model.add(MaxPooling2D((2, 2), strides=(2,2)))
# # layer 4
model.add(Conv2D(128, (5, 5), strides=(1,1)))
model.add(Flatten())
# layer 5
model.add(Dense(128, activation='relu'))
# layer 6
model.add(Dense(5, activation='softmax'))

opt = tf.keras.optimizers.SGD(learning_rate = 0.015, momentum = 0.9, decay = 0.0075)
model.compile(loss = "categorical_crossentropy", optimizer = opt , metrics = [tf.keras.metrics.CategoricalAccuracy()])                
model.summary()


# Save the weights using the `checkpoint_path` format
model.save_weights(checkpoint_path.format(epoch=0))

# Train the model with the TWO callbacks
history=model.fit_generator(train_it, 
          epochs=epochs,
          steps_per_epoch = (num_classes * img_per_model * patches_per_photo)/batch_size,          
          callbacks=[cp_callback, lrate],
          validation_data=val_it,
          #validation_steps = 8,
          verbose=1)
      
# print(history.history)
# with open('train_history_dict','wb') as f:
#     pickle.dump(history.history,f)
np.save('./train_history_dict_patchsize64.npy',history.history)

# LOAD THE HISTORY AS A DICT
# history=np.load('train_history_dict.npy',allow_pickle='TRUE').item()


#----------------------------------------------------------------------------------------------------------------------------------------------


# # TESTING
# # CREATING INPUT AND LABELS
# X_test = []
# Y_test = []
# for features,label in testing_data :
#   X_test.append(features)
#   Y_test.append(label)

# # PREPROCESSING
# X_test = np.array(X_test).reshape(-1,IMG_SIZE,IMG_SIZE,channels)
# X_test = X_test/255.0
# Y_test = np.array(Y_test)
# print(f'Test Data shape: {np.shape(X_test)}')

# # print(f'Checkpoint models: {os.listdir(checkpoint_dir)}')
# latest = tf.train.latest_checkpoint(checkpoint_dir)
# print(f'Latest model : {latest}')

# # Create a new model instance
# model = create_model()

# # Load the previously saved weights
# model.load_weights(latest)

# Re-evaluate the model
# loss, acc = model.evaluate(X_test, Y_test, verbose=2)
# yhat = model.predict_generator(predict_it, steps=24)
loss, acc  = model.evaluate_generator(test_it)
print("Accuracy: {:5.2f}%".format(100 * acc))


# Checking label distributions
Y = train_it.classes
Y_pred = model.predict_generator(test_it)
Y_pred = np.argmax(Y_pred, axis=1)
Y_test = test_it.classes
print(f'Y_train label distrib: {np.unique(Y, return_counts=True)}')
print(f'Y_test label distrib: {np.unique(Y_test, return_counts=True)}')
y_pred_distrib = np.unique(Y_pred, return_counts=True)
print(f'Y_pred_label distrib: {y_pred_distrib}')
np.save('./Y_pred_label_distrib_patchsize64.npy', y_pred_distrib)
print(f'Number of different predicted labels: {np.shape(np.unique(Y_pred, return_counts=True))}')


# Confusion Matrix
print(f"Accuracy: {accuracy_score(Y_test, Y_pred)}")
print(f"Confusion matrix: \n{confusion_matrix(Y_test, Y_pred)}")
np.save('./confusion_matrix_patchsize64.npy', confusion_matrix(Y_test, Y_pred))
print(f"Classification Report:\n {classification_report(Y_test, Y_pred)}")

model.save('./allchannel_patches100_classes5_patchsize64.h5')    


# TODOS:
# vulnerability paper uses 10^-4 learning_rate
# implement the svm and majority voting
# Increase number of classes from 5
# try out different batch-size (32 OR 128) and epochs
# save model_weights, train_dict, final_model
# DONE: (but giving 20% accuracy) try featurewise_center=True in imagegenerator: for that you need mean; use train_it to pick up a large batch and calc the mean
# DONE: should we give activation function in the conv layers? gave relu in each conv layer, didn't work


