import numpy as np
import os
import random
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, AveragePooling2D
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.callbacks import Callback,ModelCheckpoint,LearningRateScheduler
from keras.backend.tensorflow_backend import set_session
import pickle
import math


#DYNAMICALLY GROW THE GPU MEMORY
print(tf.test.is_gpu_available(cuda_only=True))
config = tf.compat.v1.ConfigProto()
config.gpu_options.per_process_gpu_memory_fraction = 0.4  # 0.6 sometimes works better for folks
config.gpu_options.allow_growth = True      
sess =  tf.compat.v1.InteractiveSession(config=config)
set_session(sess)
os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'


channels = 3
IMG_SIZE = 224
DATADIR = "/home/mtech/2020/satyaki_ghosh/datasets/VISION"
CATEGORIES = [
    "D01_Samsung_GalaxyS3Mini",
    "D02_Apple_iPhone4s",
    "D03_Huawei_P9",
    "D04_LG_D290",
    "D05_Apple_iPhone5c"]


# LOADING THE DATSET
with open('training_data.npy','rb') as f:
    dummy = np.load(f, allow_pickle=True)
dataset = list(dummy)


# TRAIN-TEST SPLIT AND SHUFFLE THE PATCHES : (train,val,test) = (0.8,0.1,0.1)
random.shuffle(dataset)
split_ratio = 0.7
split_num = int(len(dataset) * split_ratio)
print(type(split_num))
print(split_num)
training_data = dataset[0:split_num]
testing_data = dataset[split_num:]


# CREATING INPUT AND LABELS
X = []
Y = []
for features,label in training_data :
  X.append(features)
  Y.append(label)


# PREPROCESSING
X = np.array(X).reshape(-1,IMG_SIZE,IMG_SIZE,channels)
X = X/255.0
Y = np.array(Y)



# TO DECAY THE LEARNING RATE WITH INCREASING EPOCHS
def step_decay(epoch):
  initial_lrate = 0.001
  drop = 0.5
  epochs_drop = 5.0
  lrate = initial_lrate * math.pow(drop, math.floor((1 + epoch) / epochs_drop))
  return lrate

lrate = LearningRateScheduler(step_decay)

# INITIALIZING FILTERS TO APPLY ON PATCHES
num_filter=3
w = np.random.rand(5,5,channels,num_filter) #changing the number of filters change accordingly the last number 
wgt = w
bias = np.zeros(num_filter)


# RAJESH'S CODE (only next line):
#history = model.fit(X,Y,batch_size = 64, epochs = 70,callbacks = [norm_callback], validation_split = 0.1, verbose = 1)

batch_size = 32
epochs = 80

# Include the epoch in the file name (uses `str.format`)
checkpoint_path = "training_1/cp_{epoch:04d}.ckpt"
checkpoint_dir = os.path.dirname(checkpoint_path)
checkpoint_epoch_freq = 1

# Create a callback that saves the model's weights every 5 epochs
cp_callback = tf.keras.callbacks.ModelCheckpoint(
    filepath=checkpoint_path, 
    verbose=1, 
    save_weights_only=True,
    save_freq='epoch' # checkpoint_epoch_freq*batch_size
  )

# Create a new model instance
import sys 
import os
sys.path.append(os.path.abspath("/home/mtech/2020/satyaki_ghosh/codes/vulnerability_camera/DenseNet"))

import densenet

image_dim = (IMG_SIZE, IMG_SIZE, 3)

# MODEL A: Training from scratch with classes=5:
# (1) 5x5 conf_matrix but acc=0.81 if include_top=True and weights is not mentioned and img_size=32
# (2) big conf_matrix and acc=0.69 if include_top=false and img_size=224
# (3) 5x5 conf_matrix, include_top=True and img_size=224 but acc fluctuating a lot during training epochs
#     but it finally gave the 94% accuracy for training_1/cp_0069.ckpt
model = densenet.DenseNet(input_shape=image_dim, depth=121, nb_dense_block=4, growth_rate=32, nb_filter=64,
                    nb_layers_per_block=[6, 12, 24, 16], bottleneck=True, reduction=0.5,
                    dropout_rate=0.0, weight_decay=1e-4, subsample_initial_block=True,
                    include_top=True, input_tensor=None,   # weights=None,
                    classes=5)



# MODEL B: Loading ImageNet trained model with classes=5:
# (1) acc=0.3 and fluctuating a lot during training (not sure about conf_matrix size) with img_size=224
# (2) big conf_matrix, include_top=False, img_size=224, classes=5
# model = densenet.DenseNetImageNet121(input_shape=image_dim, include_top=True, classes=5)
# for n in range(100):      # setting layers as non-trainable
#   model.layers[n].trainable = False
# for l in model.layers:
#   print(l.name, l.trainable)



opt = tf.keras.optimizers.SGD(learning_rate = 0.001, momentum = 0.9, decay = 0.0005)
model.compile(loss = "sparse_categorical_crossentropy", optimizer = opt , metrics = [tf.keras.metrics.SparseCategoricalAccuracy()])                
model.summary()


# Save the weights using the `checkpoint_path` format
# model.save_weights(checkpoint_path.format(epoch=0))

# Train the model with the TWO callbacks
history=model.fit(X,Y,epochs=epochs,batch_size=batch_size,
          callbacks=[cp_callback, lrate],
          validation_split = 0.1,verbose=1)
      
# print(history.history)
# with open('train_history_dict','wb') as f:
#     pickle.dump(history.history,f)
np.save('train_history_dict_patchsize224.npy',history.history)

# LOAD THE HISTORY AS A DICT
# history=np.load('train_history_dict.npy',allow_pickle='TRUE').item()





# TESTING
# CREATING INPUT AND LABELS
X_test = []
Y_test = []
for features,label in testing_data :
  X_test.append(features)
  Y_test.append(label)

# PREPROCESSING
X_test = np.array(X_test).reshape(-1,IMG_SIZE,IMG_SIZE,channels)
X_test = X_test/255.0
Y_test = np.array(Y_test)
print(f'Test Data shape: {np.shape(X_test)}')

# print(f'Checkpoint models: {os.listdir(checkpoint_dir)}')
latest = tf.train.latest_checkpoint(checkpoint_dir)
print(f'Latest model : {latest}')

# # Create a new model instance
# model = create_model()

# # Load the previously saved weights
# model.load_weights(latest)

# Re-evaluate the model
loss, acc = model.evaluate(X_test, Y_test, verbose=2)
print("Accuracy: {:5.2f}%".format(100 * acc))
Y_pred = model.predict(X_test)
Y_pred = np.argmax(Y_pred, axis=1)

# Checking label distributions 
print(f'Y_train label distrib: {np.unique(Y, return_counts=True)}')
print(f'Y_test label distrib: {np.unique(Y_test, return_counts=True)}')
y_pred_distrib = np.unique(Y_pred, return_counts=True)
print(f'Y_pred_label distrib: {y_pred_distrib}')
np.save('Y_pred_label_distrib_patchsize224.npy', y_pred_distrib)
print(f'Number of different predicted labels: {np.shape(np.unique(Y_pred, return_counts=True))}')


# Confusion Matrix
print(f"Accuracy: {accuracy_score(Y_test, Y_pred)}")
print(f"Confusion matrix: \n{confusion_matrix(Y_test, Y_pred)}")
np.save('confusion_matrix_patchsize224.npy', confusion_matrix(Y_test, Y_pred))
print(f"Classification Report:\n {classification_report(Y_test, Y_pred)}")

model.save('allchannel_patches100_classes5_patchsize224.h5')    


# TODOS:
# try with 40 layers,
# try xceptionnet
# try reducing lrate for fluctuating accuracy
# set layers in pre-trained model as trainable ?
# Change the IMG_SIZE to 224 : reduce learning rate
# Use imagenet-pretrained model --> Not possible with classes!=1000
# trainignng
# Increase number of classes from 5
# Increase split of train-test to 0.8
# try out different batch-size and epochs
# Try different number of layers
# FIXED : why densenet is predicting extra imagenet labels (1 to 1000) ---> would automatically improve accuracy
# save model_weights, train_dict, final_model, train_history
# changed IMG_SIZE to 32 from 224 to make sure Y_pred has only 5 classes; made include_top=True; removed weights argument

