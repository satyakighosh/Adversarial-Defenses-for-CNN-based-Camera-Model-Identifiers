RESULTS:
----------------------

Model: "xception"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            
__________________________________________________________________________________________________
block1_conv1 (Conv2D)           (None, 149, 149, 32) 864         input_1[0][0]                    
__________________________________________________________________________________________________
block1_conv1_bn (BatchNormaliza (None, 149, 149, 32) 128         block1_conv1[0][0]               
__________________________________________________________________________________________________
block1_conv1_act (Activation)   (None, 149, 149, 32) 0           block1_conv1_bn[0][0]            
__________________________________________________________________________________________________
block1_conv2 (Conv2D)           (None, 147, 147, 64) 18432       block1_conv1_act[0][0]           
__________________________________________________________________________________________________
block1_conv2_bn (BatchNormaliza (None, 147, 147, 64) 256         block1_conv2[0][0]               
__________________________________________________________________________________________________
block1_conv2_act (Activation)   (None, 147, 147, 64) 0           block1_conv2_bn[0][0]            
__________________________________________________________________________________________________
block2_sepconv1 (SeparableConv2 (None, 147, 147, 128 8768        block1_conv2_act[0][0]           
__________________________________________________________________________________________________
block2_sepconv1_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv1[0][0]            
__________________________________________________________________________________________________
block2_sepconv2_act (Activation (None, 147, 147, 128 0           block2_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block2_sepconv2 (SeparableConv2 (None, 147, 147, 128 17536       block2_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block2_sepconv2_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv2[0][0]            
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 74, 74, 128)  8192        block1_conv2_act[0][0]           
__________________________________________________________________________________________________
block2_pool (MaxPooling2D)      (None, 74, 74, 128)  0           block2_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 74, 74, 128)  512         conv2d[0][0]                     
__________________________________________________________________________________________________
add (Add)                       (None, 74, 74, 128)  0           block2_pool[0][0]                
                                                                 batch_normalization[0][0]        
__________________________________________________________________________________________________
block3_sepconv1_act (Activation (None, 74, 74, 128)  0           add[0][0]                        
__________________________________________________________________________________________________
block3_sepconv1 (SeparableConv2 (None, 74, 74, 256)  33920       block3_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block3_sepconv1_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv1[0][0]            
__________________________________________________________________________________________________
block3_sepconv2_act (Activation (None, 74, 74, 256)  0           block3_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block3_sepconv2 (SeparableConv2 (None, 74, 74, 256)  67840       block3_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block3_sepconv2_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv2[0][0]            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 37, 37, 256)  32768       add[0][0]                        
__________________________________________________________________________________________________
block3_pool (MaxPooling2D)      (None, 37, 37, 256)  0           block3_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 37, 37, 256)  1024        conv2d_1[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 37, 37, 256)  0           block3_pool[0][0]                
                                                                 batch_normalization_1[0][0]      
__________________________________________________________________________________________________
block4_sepconv1_act (Activation (None, 37, 37, 256)  0           add_1[0][0]                      
__________________________________________________________________________________________________
block4_sepconv1 (SeparableConv2 (None, 37, 37, 728)  188672      block4_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block4_sepconv1_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv1[0][0]            
__________________________________________________________________________________________________
block4_sepconv2_act (Activation (None, 37, 37, 728)  0           block4_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block4_sepconv2 (SeparableConv2 (None, 37, 37, 728)  536536      block4_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block4_sepconv2_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv2[0][0]            
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 19, 19, 728)  186368      add_1[0][0]                      
__________________________________________________________________________________________________
block4_pool (MaxPooling2D)      (None, 19, 19, 728)  0           block4_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 19, 19, 728)  2912        conv2d_2[0][0]                   
__________________________________________________________________________________________________
add_2 (Add)                     (None, 19, 19, 728)  0           block4_pool[0][0]                
                                                                 batch_normalization_2[0][0]      
__________________________________________________________________________________________________
block5_sepconv1_act (Activation (None, 19, 19, 728)  0           add_2[0][0]                      
__________________________________________________________________________________________________
block5_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block5_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv1[0][0]            
__________________________________________________________________________________________________
block5_sepconv2_act (Activation (None, 19, 19, 728)  0           block5_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block5_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block5_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv2[0][0]            
__________________________________________________________________________________________________
block5_sepconv3_act (Activation (None, 19, 19, 728)  0           block5_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
block5_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv3_act[0][0]        
__________________________________________________________________________________________________
block5_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv3[0][0]            
__________________________________________________________________________________________________
add_3 (Add)                     (None, 19, 19, 728)  0           block5_sepconv3_bn[0][0]         
                                                                 add_2[0][0]                      
__________________________________________________________________________________________________
block6_sepconv1_act (Activation (None, 19, 19, 728)  0           add_3[0][0]                      
__________________________________________________________________________________________________
block6_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block6_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv1[0][0]            
__________________________________________________________________________________________________
block6_sepconv2_act (Activation (None, 19, 19, 728)  0           block6_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block6_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block6_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv2[0][0]            
__________________________________________________________________________________________________
block6_sepconv3_act (Activation (None, 19, 19, 728)  0           block6_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
block6_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv3_act[0][0]        
__________________________________________________________________________________________________
block6_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv3[0][0]            
__________________________________________________________________________________________________
add_4 (Add)                     (None, 19, 19, 728)  0           block6_sepconv3_bn[0][0]         
                                                                 add_3[0][0]                      
__________________________________________________________________________________________________
block7_sepconv1_act (Activation (None, 19, 19, 728)  0           add_4[0][0]                      
__________________________________________________________________________________________________
block7_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block7_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv1[0][0]            
__________________________________________________________________________________________________
block7_sepconv2_act (Activation (None, 19, 19, 728)  0           block7_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block7_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block7_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv2[0][0]            
__________________________________________________________________________________________________
block7_sepconv3_act (Activation (None, 19, 19, 728)  0           block7_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
block7_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv3_act[0][0]        
__________________________________________________________________________________________________
block7_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv3[0][0]            
__________________________________________________________________________________________________
add_5 (Add)                     (None, 19, 19, 728)  0           block7_sepconv3_bn[0][0]         
                                                                 add_4[0][0]                      
__________________________________________________________________________________________________
block8_sepconv1_act (Activation (None, 19, 19, 728)  0           add_5[0][0]                      
__________________________________________________________________________________________________
block8_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block8_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv1[0][0]            
__________________________________________________________________________________________________
block8_sepconv2_act (Activation (None, 19, 19, 728)  0           block8_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block8_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block8_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv2[0][0]            
__________________________________________________________________________________________________
block8_sepconv3_act (Activation (None, 19, 19, 728)  0           block8_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
block8_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv3_act[0][0]        
__________________________________________________________________________________________________
block8_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv3[0][0]            
__________________________________________________________________________________________________
add_6 (Add)                     (None, 19, 19, 728)  0           block8_sepconv3_bn[0][0]         
                                                                 add_5[0][0]                      
__________________________________________________________________________________________________
block9_sepconv1_act (Activation (None, 19, 19, 728)  0           add_6[0][0]                      
__________________________________________________________________________________________________
block9_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block9_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv1[0][0]            
__________________________________________________________________________________________________
block9_sepconv2_act (Activation (None, 19, 19, 728)  0           block9_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block9_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block9_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv2[0][0]            
__________________________________________________________________________________________________
block9_sepconv3_act (Activation (None, 19, 19, 728)  0           block9_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
block9_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv3_act[0][0]        
__________________________________________________________________________________________________
block9_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv3[0][0]            
__________________________________________________________________________________________________
add_7 (Add)                     (None, 19, 19, 728)  0           block9_sepconv3_bn[0][0]         
                                                                 add_6[0][0]                      
__________________________________________________________________________________________________
block10_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_7[0][0]                      
__________________________________________________________________________________________________
block10_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv1_act[0][0]       
__________________________________________________________________________________________________
block10_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv1[0][0]           
__________________________________________________________________________________________________
block10_sepconv2_act (Activatio (None, 19, 19, 728)  0           block10_sepconv1_bn[0][0]        
__________________________________________________________________________________________________
block10_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv2_act[0][0]       
__________________________________________________________________________________________________
block10_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv2[0][0]           
__________________________________________________________________________________________________
block10_sepconv3_act (Activatio (None, 19, 19, 728)  0           block10_sepconv2_bn[0][0]        
__________________________________________________________________________________________________
block10_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv3_act[0][0]       
__________________________________________________________________________________________________
block10_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv3[0][0]           
__________________________________________________________________________________________________
add_8 (Add)                     (None, 19, 19, 728)  0           block10_sepconv3_bn[0][0]        
                                                                 add_7[0][0]                      
__________________________________________________________________________________________________
block11_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_8[0][0]                      
__________________________________________________________________________________________________
block11_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv1_act[0][0]       
__________________________________________________________________________________________________
block11_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv1[0][0]           
__________________________________________________________________________________________________
block11_sepconv2_act (Activatio (None, 19, 19, 728)  0           block11_sepconv1_bn[0][0]        
__________________________________________________________________________________________________
block11_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv2_act[0][0]       
__________________________________________________________________________________________________
block11_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv2[0][0]           
__________________________________________________________________________________________________
block11_sepconv3_act (Activatio (None, 19, 19, 728)  0           block11_sepconv2_bn[0][0]        
__________________________________________________________________________________________________
block11_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv3_act[0][0]       
__________________________________________________________________________________________________
block11_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv3[0][0]           
__________________________________________________________________________________________________
add_9 (Add)                     (None, 19, 19, 728)  0           block11_sepconv3_bn[0][0]        
                                                                 add_8[0][0]                      
__________________________________________________________________________________________________
block12_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_9[0][0]                      
__________________________________________________________________________________________________
block12_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv1_act[0][0]       
__________________________________________________________________________________________________
block12_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv1[0][0]           
__________________________________________________________________________________________________
block12_sepconv2_act (Activatio (None, 19, 19, 728)  0           block12_sepconv1_bn[0][0]        
__________________________________________________________________________________________________
block12_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv2_act[0][0]       
__________________________________________________________________________________________________
block12_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv2[0][0]           
__________________________________________________________________________________________________
block12_sepconv3_act (Activatio (None, 19, 19, 728)  0           block12_sepconv2_bn[0][0]        
__________________________________________________________________________________________________
block12_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv3_act[0][0]       
__________________________________________________________________________________________________
block12_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv3[0][0]           
__________________________________________________________________________________________________
add_10 (Add)                    (None, 19, 19, 728)  0           block12_sepconv3_bn[0][0]        
                                                                 add_9[0][0]                      
__________________________________________________________________________________________________
block13_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_10[0][0]                     
__________________________________________________________________________________________________
block13_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block13_sepconv1_act[0][0]       
__________________________________________________________________________________________________
block13_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block13_sepconv1[0][0]           
__________________________________________________________________________________________________
block13_sepconv2_act (Activatio (None, 19, 19, 728)  0           block13_sepconv1_bn[0][0]        
__________________________________________________________________________________________________
block13_sepconv2 (SeparableConv (None, 19, 19, 1024) 752024      block13_sepconv2_act[0][0]       
__________________________________________________________________________________________________
block13_sepconv2_bn (BatchNorma (None, 19, 19, 1024) 4096        block13_sepconv2[0][0]           
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 10, 10, 1024) 745472      add_10[0][0]                     
__________________________________________________________________________________________________
block13_pool (MaxPooling2D)     (None, 10, 10, 1024) 0           block13_sepconv2_bn[0][0]        
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 10, 10, 1024) 4096        conv2d_3[0][0]                   
__________________________________________________________________________________________________
add_11 (Add)                    (None, 10, 10, 1024) 0           block13_pool[0][0]               
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
block14_sepconv1 (SeparableConv (None, 10, 10, 1536) 1582080     add_11[0][0]                     
__________________________________________________________________________________________________
block14_sepconv1_bn (BatchNorma (None, 10, 10, 1536) 6144        block14_sepconv1[0][0]           
__________________________________________________________________________________________________
block14_sepconv1_act (Activatio (None, 10, 10, 1536) 0           block14_sepconv1_bn[0][0]        
__________________________________________________________________________________________________
block14_sepconv2 (SeparableConv (None, 10, 10, 2048) 3159552     block14_sepconv1_act[0][0]       
__________________________________________________________________________________________________
block14_sepconv2_bn (BatchNorma (None, 10, 10, 2048) 8192        block14_sepconv2[0][0]           
__________________________________________________________________________________________________
block14_sepconv2_act (Activatio (None, 10, 10, 2048) 0           block14_sepconv2_bn[0][0]        
__________________________________________________________________________________________________
avg_pool (GlobalAveragePooling2 (None, 2048)         0           block14_sepconv2_act[0][0]       
__________________________________________________________________________________________________
predictions (Dense)             (None, 5)            10245       avg_pool[0][0]                   
==================================================================================================
Total params: 20,871,725
Trainable params: 20,817,197
Non-trainable params: 54,528
__________________________________________________________________________________________________
Epoch 1/80
2022-04-14 17:59:53.020356: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2022-04-14 17:59:59.265751: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2343/2343 [============================>.] - ETA: 0s - loss: 1.0517 - categorical_accuracy: 0.5811     
Epoch 00001: saving model to xceptionNet/training_1/cp_0001.ckpt
2344/2343 [==============================] - 2813s 1s/step - loss: 1.0516 - categorical_accuracy: 0.5812 - val_loss: 1.7001 - val_categorical_accuracy: 0.4414
Epoch 2/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.6891 - categorical_accuracy: 0.7369   
Epoch 00002: saving model to xceptionNet/training_1/cp_0002.ckpt
2344/2343 [==============================] - 2495s 1s/step - loss: 0.6891 - categorical_accuracy: 0.7369 - val_loss: 1.3077 - val_categorical_accuracy: 0.6133
Epoch 3/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.4789 - categorical_accuracy: 0.8200   
Epoch 00003: saving model to xceptionNet/training_1/cp_0003.ckpt
2344/2343 [==============================] - 2159s 921ms/step - loss: 0.4788 - categorical_accuracy: 0.8201 - val_loss: 0.9435 - val_categorical_accuracy: 0.7109
Epoch 4/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.3636 - categorical_accuracy: 0.8651   
Epoch 00004: saving model to xceptionNet/training_1/cp_0004.ckpt
2344/2343 [==============================] - 2113s 901ms/step - loss: 0.3635 - categorical_accuracy: 0.8651 - val_loss: 0.6210 - val_categorical_accuracy: 0.7617
Epoch 5/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.2573 - categorical_accuracy: 0.9066   
Epoch 00005: saving model to xceptionNet/training_1/cp_0005.ckpt
2344/2343 [==============================] - 2116s 903ms/step - loss: 0.2572 - categorical_accuracy: 0.9066 - val_loss: 0.4820 - val_categorical_accuracy: 0.8359
Epoch 6/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.2220 - categorical_accuracy: 0.9209   
Epoch 00006: saving model to xceptionNet/training_1/cp_0006.ckpt
2344/2343 [==============================] - 2135s 911ms/step - loss: 0.2221 - categorical_accuracy: 0.9209 - val_loss: 0.5117 - val_categorical_accuracy: 0.8203
Epoch 7/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.2021 - categorical_accuracy: 0.9277   
Epoch 00007: saving model to xceptionNet/training_1/cp_0007.ckpt
2344/2343 [==============================] - 2135s 911ms/step - loss: 0.2021 - categorical_accuracy: 0.9277 - val_loss: 0.4199 - val_categorical_accuracy: 0.8438
Epoch 8/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1869 - categorical_accuracy: 0.9335   
Epoch 00008: saving model to xceptionNet/training_1/cp_0008.ckpt
2344/2343 [==============================] - 2148s 916ms/step - loss: 0.1869 - categorical_accuracy: 0.9335 - val_loss: 0.3840 - val_categorical_accuracy: 0.8594
Epoch 9/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1691 - categorical_accuracy: 0.9403   
Epoch 00009: saving model to xceptionNet/training_1/cp_0009.ckpt
2344/2343 [==============================] - 2127s 907ms/step - loss: 0.1692 - categorical_accuracy: 0.9402 - val_loss: 0.3908 - val_categorical_accuracy: 0.8633
Epoch 10/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1475 - categorical_accuracy: 0.9485   
Epoch 00010: saving model to xceptionNet/training_1/cp_0010.ckpt
2344/2343 [==============================] - 2120s 904ms/step - loss: 0.1475 - categorical_accuracy: 0.9485 - val_loss: 0.3514 - val_categorical_accuracy: 0.8789
Epoch 11/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1378 - categorical_accuracy: 0.9525   
Epoch 00011: saving model to xceptionNet/training_1/cp_0011.ckpt
2344/2343 [==============================] - 2131s 909ms/step - loss: 0.1378 - categorical_accuracy: 0.9525 - val_loss: 0.3361 - val_categorical_accuracy: 0.8945
Epoch 12/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1345 - categorical_accuracy: 0.9535   
Epoch 00012: saving model to xceptionNet/training_1/cp_0012.ckpt
2344/2343 [==============================] - 2091s 892ms/step - loss: 0.1346 - categorical_accuracy: 0.9535 - val_loss: 0.3358 - val_categorical_accuracy: 0.8984
Epoch 13/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1270 - categorical_accuracy: 0.9573   
Epoch 00013: saving model to xceptionNet/training_1/cp_0013.ckpt
2344/2343 [==============================] - 2094s 894ms/step - loss: 0.1270 - categorical_accuracy: 0.9572 - val_loss: 0.3550 - val_categorical_accuracy: 0.8906
Epoch 14/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1250 - categorical_accuracy: 0.9568   
Epoch 00014: saving model to xceptionNet/training_1/cp_0014.ckpt
2344/2343 [==============================] - 2095s 894ms/step - loss: 0.1250 - categorical_accuracy: 0.9568 - val_loss: 0.3053 - val_categorical_accuracy: 0.8945
Epoch 15/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1194 - categorical_accuracy: 0.9596   
Epoch 00015: saving model to xceptionNet/training_1/cp_0015.ckpt
2344/2343 [==============================] - 2094s 893ms/step - loss: 0.1194 - categorical_accuracy: 0.9596 - val_loss: 0.2882 - val_categorical_accuracy: 0.9023
Epoch 16/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1142 - categorical_accuracy: 0.9605   
Epoch 00016: saving model to xceptionNet/training_1/cp_0016.ckpt
2344/2343 [==============================] - 2089s 891ms/step - loss: 0.1142 - categorical_accuracy: 0.9605 - val_loss: 0.2850 - val_categorical_accuracy: 0.9023
Epoch 17/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1129 - categorical_accuracy: 0.9608   
Epoch 00017: saving model to xceptionNet/training_1/cp_0017.ckpt
2344/2343 [==============================] - 2091s 892ms/step - loss: 0.1129 - categorical_accuracy: 0.9608 - val_loss: 0.3001 - val_categorical_accuracy: 0.8828
Epoch 18/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1129 - categorical_accuracy: 0.9607   
Epoch 00018: saving model to xceptionNet/training_1/cp_0018.ckpt
2344/2343 [==============================] - 2093s 893ms/step - loss: 0.1129 - categorical_accuracy: 0.9607 - val_loss: 0.2894 - val_categorical_accuracy: 0.8906
Epoch 19/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1092 - categorical_accuracy: 0.9628   
Epoch 00019: saving model to xceptionNet/training_1/cp_0019.ckpt
2344/2343 [==============================] - 2093s 893ms/step - loss: 0.1092 - categorical_accuracy: 0.9628 - val_loss: 0.3114 - val_categorical_accuracy: 0.8867
Epoch 20/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1084 - categorical_accuracy: 0.9633   
Epoch 00020: saving model to xceptionNet/training_1/cp_0020.ckpt
2344/2343 [==============================] - 2098s 895ms/step - loss: 0.1084 - categorical_accuracy: 0.9633 - val_loss: 0.3092 - val_categorical_accuracy: 0.8867
Epoch 21/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1063 - categorical_accuracy: 0.9643   
Epoch 00021: saving model to xceptionNet/training_1/cp_0021.ckpt
2344/2343 [==============================] - 2092s 892ms/step - loss: 0.1063 - categorical_accuracy: 0.9643 - val_loss: 0.2914 - val_categorical_accuracy: 0.8867
Epoch 22/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1085 - categorical_accuracy: 0.9635   
Epoch 00022: saving model to xceptionNet/training_1/cp_0022.ckpt
2344/2343 [==============================] - 2099s 895ms/step - loss: 0.1085 - categorical_accuracy: 0.9635 - val_loss: 0.2842 - val_categorical_accuracy: 0.9023
Epoch 23/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1061 - categorical_accuracy: 0.9638   
Epoch 00023: saving model to xceptionNet/training_1/cp_0023.ckpt
2344/2343 [==============================] - 2093s 893ms/step - loss: 0.1061 - categorical_accuracy: 0.9638 - val_loss: 0.2946 - val_categorical_accuracy: 0.8867
Epoch 24/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1051 - categorical_accuracy: 0.9647   
Epoch 00024: saving model to xceptionNet/training_1/cp_0024.ckpt
2344/2343 [==============================] - 2107s 899ms/step - loss: 0.1051 - categorical_accuracy: 0.9647 - val_loss: 0.2929 - val_categorical_accuracy: 0.8945
Epoch 25/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1037 - categorical_accuracy: 0.9653   
Epoch 00025: saving model to xceptionNet/training_1/cp_0025.ckpt
2344/2343 [==============================] - 2107s 899ms/step - loss: 0.1037 - categorical_accuracy: 0.9653 - val_loss: 0.3045 - val_categorical_accuracy: 0.8867
Epoch 26/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1049 - categorical_accuracy: 0.9651   
Epoch 00026: saving model to xceptionNet/training_1/cp_0026.ckpt
2344/2343 [==============================] - 2099s 896ms/step - loss: 0.1049 - categorical_accuracy: 0.9652 - val_loss: 0.2937 - val_categorical_accuracy: 0.8867
Epoch 27/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1060 - categorical_accuracy: 0.9641   
Epoch 00027: saving model to xceptionNet/training_1/cp_0027.ckpt
2344/2343 [==============================] - 2095s 894ms/step - loss: 0.1060 - categorical_accuracy: 0.9641 - val_loss: 0.2893 - val_categorical_accuracy: 0.8906
Epoch 28/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1032 - categorical_accuracy: 0.9659   
Epoch 00028: saving model to xceptionNet/training_1/cp_0028.ckpt
2344/2343 [==============================] - 2097s 894ms/step - loss: 0.1032 - categorical_accuracy: 0.9659 - val_loss: 0.2974 - val_categorical_accuracy: 0.8867
Epoch 29/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1039 - categorical_accuracy: 0.9649   
Epoch 00029: saving model to xceptionNet/training_1/cp_0029.ckpt
2344/2343 [==============================] - 2110s 900ms/step - loss: 0.1038 - categorical_accuracy: 0.9649 - val_loss: 0.2886 - val_categorical_accuracy: 0.8945
Epoch 30/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1032 - categorical_accuracy: 0.9652   
Epoch 00030: saving model to xceptionNet/training_1/cp_0030.ckpt
2344/2343 [==============================] - 2115s 902ms/step - loss: 0.1032 - categorical_accuracy: 0.9652 - val_loss: 0.2876 - val_categorical_accuracy: 0.8945
Epoch 31/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1025 - categorical_accuracy: 0.9663   
Epoch 00031: saving model to xceptionNet/training_1/cp_0031.ckpt
2344/2343 [==============================] - 2108s 899ms/step - loss: 0.1026 - categorical_accuracy: 0.9662 - val_loss: 0.2848 - val_categorical_accuracy: 0.9023
Epoch 32/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1042 - categorical_accuracy: 0.9653   
Epoch 00032: saving model to xceptionNet/training_1/cp_0032.ckpt
2344/2343 [==============================] - 2189s 934ms/step - loss: 0.1042 - categorical_accuracy: 0.9653 - val_loss: 0.2857 - val_categorical_accuracy: 0.8906
Epoch 33/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1013 - categorical_accuracy: 0.9667   
Epoch 00033: saving model to xceptionNet/training_1/cp_0033.ckpt
2344/2343 [==============================] - 2480s 1s/step - loss: 0.1013 - categorical_accuracy: 0.9667 - val_loss: 0.2891 - val_categorical_accuracy: 0.8984
Epoch 34/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1036 - categorical_accuracy: 0.9645   
Epoch 00034: saving model to xceptionNet/training_1/cp_0034.ckpt
2344/2343 [==============================] - 2793s 1s/step - loss: 0.1036 - categorical_accuracy: 0.9646 - val_loss: 0.2937 - val_categorical_accuracy: 0.8906
Epoch 35/80
2343/2343 [============================>.] - ETA: 1s - loss: 0.1007 - categorical_accuracy: 0.9660   
Epoch 00035: saving model to xceptionNet/training_1/cp_0035.ckpt
2344/2343 [==============================] - 3304s 1s/step - loss: 0.1007 - categorical_accuracy: 0.9659 - val_loss: 0.2893 - val_categorical_accuracy: 0.8945
Epoch 36/80
2343/2343 [============================>.] - ETA: 1s - loss: 0.1023 - categorical_accuracy: 0.9659   
Epoch 00036: saving model to xceptionNet/training_1/cp_0036.ckpt
2344/2343 [==============================] - 3295s 1s/step - loss: 0.1024 - categorical_accuracy: 0.9659 - val_loss: 0.2921 - val_categorical_accuracy: 0.8945
Epoch 37/80
2343/2343 [============================>.] - ETA: 1s - loss: 0.1016 - categorical_accuracy: 0.9666   
Epoch 00037: saving model to xceptionNet/training_1/cp_0037.ckpt
2344/2343 [==============================] - 3324s 1s/step - loss: 0.1016 - categorical_accuracy: 0.9666 - val_loss: 0.2907 - val_categorical_accuracy: 0.8867
Epoch 38/80
2343/2343 [============================>.] - ETA: 1s - loss: 0.1018 - categorical_accuracy: 0.9655   
Epoch 00038: saving model to xceptionNet/training_1/cp_0038.ckpt
2344/2343 [==============================] - 3359s 1s/step - loss: 0.1018 - categorical_accuracy: 0.9655 - val_loss: 0.2885 - val_categorical_accuracy: 0.8984
Epoch 39/80
2343/2343 [============================>.] - ETA: 1s - loss: 0.1008 - categorical_accuracy: 0.9660   
Epoch 00039: saving model to xceptionNet/training_1/cp_0039.ckpt
2344/2343 [==============================] - 3358s 1s/step - loss: 0.1007 - categorical_accuracy: 0.9660 - val_loss: 0.2912 - val_categorical_accuracy: 0.8945
Epoch 40/80
2343/2343 [============================>.] - ETA: 1s - loss: 0.1037 - categorical_accuracy: 0.9653   
Epoch 00040: saving model to xceptionNet/training_1/cp_0040.ckpt
2344/2343 [==============================] - 3382s 1s/step - loss: 0.1037 - categorical_accuracy: 0.9653 - val_loss: 0.2908 - val_categorical_accuracy: 0.8867
Epoch 41/80
2343/2343 [============================>.] - ETA: 1s - loss: 0.1022 - categorical_accuracy: 0.9655   
Epoch 00041: saving model to xceptionNet/training_1/cp_0041.ckpt
2344/2343 [==============================] - 3363s 1s/step - loss: 0.1022 - categorical_accuracy: 0.9655 - val_loss: 0.2864 - val_categorical_accuracy: 0.8945
Epoch 42/80
2343/2343 [============================>.] - ETA: 1s - loss: 0.1009 - categorical_accuracy: 0.9660     
Epoch 00042: saving model to xceptionNet/training_1/cp_0042.ckpt
2344/2343 [==============================] - 3358s 1s/step - loss: 0.1009 - categorical_accuracy: 0.9660 - val_loss: 0.2875 - val_categorical_accuracy: 0.8984
Epoch 43/80
2343/2343 [============================>.] - ETA: 1s - loss: 0.1002 - categorical_accuracy: 0.9664     
Epoch 00043: saving model to xceptionNet/training_1/cp_0043.ckpt
2344/2343 [==============================] - 3371s 1s/step - loss: 0.1002 - categorical_accuracy: 0.9664 - val_loss: 0.2950 - val_categorical_accuracy: 0.8867
Epoch 44/80
2343/2343 [============================>.] - ETA: 1s - loss: 0.1005 - categorical_accuracy: 0.9669   
Epoch 00044: saving model to xceptionNet/training_1/cp_0044.ckpt
2344/2343 [==============================] - 3348s 1s/step - loss: 0.1005 - categorical_accuracy: 0.9670 - val_loss: 0.2880 - val_categorical_accuracy: 0.8867
Epoch 45/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1020 - categorical_accuracy: 0.9656   
Epoch 00045: saving model to xceptionNet/training_1/cp_0045.ckpt
2344/2343 [==============================] - 2122s 905ms/step - loss: 0.1020 - categorical_accuracy: 0.9656 - val_loss: 0.2911 - val_categorical_accuracy: 0.8945
Epoch 46/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.0995 - categorical_accuracy: 0.9670   
Epoch 00046: saving model to xceptionNet/training_1/cp_0046.ckpt
2344/2343 [==============================] - 1412s 602ms/step - loss: 0.0995 - categorical_accuracy: 0.9670 - val_loss: 0.2919 - val_categorical_accuracy: 0.8906
Epoch 47/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1014 - categorical_accuracy: 0.9660   
Epoch 00047: saving model to xceptionNet/training_1/cp_0047.ckpt
2344/2343 [==============================] - 1426s 608ms/step - loss: 0.1014 - categorical_accuracy: 0.9660 - val_loss: 0.2914 - val_categorical_accuracy: 0.8906
Epoch 48/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.0983 - categorical_accuracy: 0.9677   
Epoch 00048: saving model to xceptionNet/training_1/cp_0048.ckpt
2344/2343 [==============================] - 1348s 575ms/step - loss: 0.0983 - categorical_accuracy: 0.9677 - val_loss: 0.2841 - val_categorical_accuracy: 0.8906
Epoch 49/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1029 - categorical_accuracy: 0.9653   
Epoch 00049: saving model to xceptionNet/training_1/cp_0049.ckpt
2344/2343 [==============================] - 2294s 979ms/step - loss: 0.1029 - categorical_accuracy: 0.9652 - val_loss: 0.2897 - val_categorical_accuracy: 0.8906
Epoch 50/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1022 - categorical_accuracy: 0.9665   
Epoch 00050: saving model to xceptionNet/training_1/cp_0050.ckpt
2344/2343 [==============================] - 2334s 996ms/step - loss: 0.1021 - categorical_accuracy: 0.9665 - val_loss: 0.2946 - val_categorical_accuracy: 0.8867
Epoch 51/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1019 - categorical_accuracy: 0.9669   
Epoch 00051: saving model to xceptionNet/training_1/cp_0051.ckpt
2344/2343 [==============================] - 2332s 995ms/step - loss: 0.1019 - categorical_accuracy: 0.9669 - val_loss: 0.2927 - val_categorical_accuracy: 0.8867
Epoch 52/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1009 - categorical_accuracy: 0.9665   
Epoch 00052: saving model to xceptionNet/training_1/cp_0052.ckpt
2344/2343 [==============================] - 2312s 986ms/step - loss: 0.1009 - categorical_accuracy: 0.9666 - val_loss: 0.2877 - val_categorical_accuracy: 0.9023
Epoch 53/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1026 - categorical_accuracy: 0.9656   
Epoch 00053: saving model to xceptionNet/training_1/cp_0053.ckpt
2344/2343 [==============================] - 2307s 984ms/step - loss: 0.1026 - categorical_accuracy: 0.9656 - val_loss: 0.2880 - val_categorical_accuracy: 0.8906
Epoch 54/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1007 - categorical_accuracy: 0.9666   
Epoch 00054: saving model to xceptionNet/training_1/cp_0054.ckpt
2344/2343 [==============================] - 2303s 983ms/step - loss: 0.1007 - categorical_accuracy: 0.9666 - val_loss: 0.2893 - val_categorical_accuracy: 0.8945
Epoch 55/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1048 - categorical_accuracy: 0.9641   
Epoch 00055: saving model to xceptionNet/training_1/cp_0055.ckpt
2344/2343 [==============================] - 2313s 987ms/step - loss: 0.1047 - categorical_accuracy: 0.9641 - val_loss: 0.2902 - val_categorical_accuracy: 0.8906
Epoch 56/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.0990 - categorical_accuracy: 0.9673   
Epoch 00056: saving model to xceptionNet/training_1/cp_0056.ckpt
2344/2343 [==============================] - 2298s 980ms/step - loss: 0.0990 - categorical_accuracy: 0.9673 - val_loss: 0.2924 - val_categorical_accuracy: 0.8906
Epoch 57/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1016 - categorical_accuracy: 0.9660   
Epoch 00057: saving model to xceptionNet/training_1/cp_0057.ckpt
2344/2343 [==============================] - 2297s 980ms/step - loss: 0.1016 - categorical_accuracy: 0.9660 - val_loss: 0.2916 - val_categorical_accuracy: 0.8867
Epoch 58/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1013 - categorical_accuracy: 0.9657   
Epoch 00058: saving model to xceptionNet/training_1/cp_0058.ckpt
2344/2343 [==============================] - 2300s 981ms/step - loss: 0.1013 - categorical_accuracy: 0.9658 - val_loss: 0.2919 - val_categorical_accuracy: 0.8945
Epoch 59/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1030 - categorical_accuracy: 0.9653   
Epoch 00059: saving model to xceptionNet/training_1/cp_0059.ckpt
2344/2343 [==============================] - 2352s 1s/step - loss: 0.1030 - categorical_accuracy: 0.9654 - val_loss: 0.2893 - val_categorical_accuracy: 0.8867
Epoch 60/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1017 - categorical_accuracy: 0.9661   
Epoch 00060: saving model to xceptionNet/training_1/cp_0060.ckpt
2344/2343 [==============================] - 2351s 1s/step - loss: 0.1017 - categorical_accuracy: 0.9661 - val_loss: 0.2923 - val_categorical_accuracy: 0.8828
Epoch 61/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1009 - categorical_accuracy: 0.9665   
Epoch 00061: saving model to xceptionNet/training_1/cp_0061.ckpt
2344/2343 [==============================] - 2341s 999ms/step - loss: 0.1008 - categorical_accuracy: 0.9666 - val_loss: 0.2854 - val_categorical_accuracy: 0.8945
Epoch 62/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1016 - categorical_accuracy: 0.9661   
Epoch 00062: saving model to xceptionNet/training_1/cp_0062.ckpt
2344/2343 [==============================] - 1778s 759ms/step - loss: 0.1015 - categorical_accuracy: 0.9661 - val_loss: 0.2896 - val_categorical_accuracy: 0.8906
Epoch 63/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1020 - categorical_accuracy: 0.9656   
Epoch 00063: saving model to xceptionNet/training_1/cp_0063.ckpt
2344/2343 [==============================] - 1459s 623ms/step - loss: 0.1020 - categorical_accuracy: 0.9656 - val_loss: 0.2845 - val_categorical_accuracy: 0.8906
Epoch 64/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1023 - categorical_accuracy: 0.9651   
Epoch 00064: saving model to xceptionNet/training_1/cp_0064.ckpt
2344/2343 [==============================] - 1443s 616ms/step - loss: 0.1023 - categorical_accuracy: 0.9651 - val_loss: 0.2872 - val_categorical_accuracy: 0.8945
Epoch 65/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1033 - categorical_accuracy: 0.9654   
Epoch 00065: saving model to xceptionNet/training_1/cp_0065.ckpt
2344/2343 [==============================] - 1443s 616ms/step - loss: 0.1033 - categorical_accuracy: 0.9654 - val_loss: 0.2936 - val_categorical_accuracy: 0.8867
Epoch 66/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1038 - categorical_accuracy: 0.9653   
Epoch 00066: saving model to xceptionNet/training_1/cp_0066.ckpt
2344/2343 [==============================] - 2387s 1s/step - loss: 0.1038 - categorical_accuracy: 0.9653 - val_loss: 0.2920 - val_categorical_accuracy: 0.8867
Epoch 67/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1019 - categorical_accuracy: 0.9655   
Epoch 00067: saving model to xceptionNet/training_1/cp_0067.ckpt
2344/2343 [==============================] - 1609s 686ms/step - loss: 0.1019 - categorical_accuracy: 0.9655 - val_loss: 0.2855 - val_categorical_accuracy: 0.8906
Epoch 68/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1022 - categorical_accuracy: 0.9652   
Epoch 00068: saving model to xceptionNet/training_1/cp_0068.ckpt
2344/2343 [==============================] - 1306s 557ms/step - loss: 0.1022 - categorical_accuracy: 0.9652 - val_loss: 0.2897 - val_categorical_accuracy: 0.8945
Epoch 69/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1012 - categorical_accuracy: 0.9662   
Epoch 00069: saving model to xceptionNet/training_1/cp_0069.ckpt
2344/2343 [==============================] - 1314s 561ms/step - loss: 0.1012 - categorical_accuracy: 0.9662 - val_loss: 0.2966 - val_categorical_accuracy: 0.8867
Epoch 70/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1016 - categorical_accuracy: 0.9663   
Epoch 00070: saving model to xceptionNet/training_1/cp_0070.ckpt
2344/2343 [==============================] - 1289s 550ms/step - loss: 0.1016 - categorical_accuracy: 0.9663 - val_loss: 0.2850 - val_categorical_accuracy: 0.8945
Epoch 71/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1047 - categorical_accuracy: 0.9650   
Epoch 00071: saving model to xceptionNet/training_1/cp_0071.ckpt
2344/2343 [==============================] - 1309s 558ms/step - loss: 0.1047 - categorical_accuracy: 0.9650 - val_loss: 0.2878 - val_categorical_accuracy: 0.8945
Epoch 72/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1028 - categorical_accuracy: 0.9653   
Epoch 00072: saving model to xceptionNet/training_1/cp_0072.ckpt
2344/2343 [==============================] - 1336s 570ms/step - loss: 0.1028 - categorical_accuracy: 0.9653 - val_loss: 0.2873 - val_categorical_accuracy: 0.8984
Epoch 73/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1016 - categorical_accuracy: 0.9659   
Epoch 00073: saving model to xceptionNet/training_1/cp_0073.ckpt
2344/2343 [==============================] - 1374s 586ms/step - loss: 0.1016 - categorical_accuracy: 0.9659 - val_loss: 0.2884 - val_categorical_accuracy: 0.8984
Epoch 74/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1033 - categorical_accuracy: 0.9651   
Epoch 00074: saving model to xceptionNet/training_1/cp_0074.ckpt
2344/2343 [==============================] - 1520s 648ms/step - loss: 0.1033 - categorical_accuracy: 0.9652 - val_loss: 0.2913 - val_categorical_accuracy: 0.8867
Epoch 75/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1010 - categorical_accuracy: 0.9662   
Epoch 00075: saving model to xceptionNet/training_1/cp_0075.ckpt
2344/2343 [==============================] - 1350s 576ms/step - loss: 0.1010 - categorical_accuracy: 0.9662 - val_loss: 0.2923 - val_categorical_accuracy: 0.8867
Epoch 76/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1013 - categorical_accuracy: 0.9661   
Epoch 00076: saving model to xceptionNet/training_1/cp_0076.ckpt
2344/2343 [==============================] - 1324s 565ms/step - loss: 0.1013 - categorical_accuracy: 0.9662 - val_loss: 0.2917 - val_categorical_accuracy: 0.8867
Epoch 77/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1036 - categorical_accuracy: 0.9650   
Epoch 00077: saving model to xceptionNet/training_1/cp_0077.ckpt
2344/2343 [==============================] - 1327s 566ms/step - loss: 0.1036 - categorical_accuracy: 0.9650 - val_loss: 0.2864 - val_categorical_accuracy: 0.8906
Epoch 78/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.0996 - categorical_accuracy: 0.9664   
Epoch 00078: saving model to xceptionNet/training_1/cp_0078.ckpt
2344/2343 [==============================] - 1309s 558ms/step - loss: 0.0996 - categorical_accuracy: 0.9664 - val_loss: 0.3038 - val_categorical_accuracy: 0.8945
Epoch 79/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1007 - categorical_accuracy: 0.9663   
Epoch 00079: saving model to xceptionNet/training_1/cp_0079.ckpt
2344/2343 [==============================] - 1333s 569ms/step - loss: 0.1007 - categorical_accuracy: 0.9663 - val_loss: 0.2900 - val_categorical_accuracy: 0.8945
Epoch 80/80
2343/2343 [============================>.] - ETA: 0s - loss: 0.1012 - categorical_accuracy: 0.9660   
Epoch 00080: saving model to xceptionNet/training_1/cp_0080.ckpt
2344/2343 [==============================] - 1322s 564ms/step - loss: 0.1012 - categorical_accuracy: 0.9661 - val_loss: 0.2862 - val_categorical_accuracy: 0.8945
Accuracy: 89.12%
Y_train label distrib: (array([0, 1, 2, 3, 4], dtype=int32), array([10556, 10540, 10552, 10554, 10566]))
Y_test label distrib: (array([0, 1, 2, 3, 4], dtype=int32), array([2468, 2222, 2224, 2224, 2222]))
Y_pred_label distrib: (array([0, 1, 2, 3, 4]), array([2347, 2163, 2207, 2339, 2304]))
Number of different predicted labels: (2, 5)
Accuracy: 0.20193661971830987
Confusion matrix: 
[[522 490 465 530 461]
 [465 424 424 469 440]
 [461 414 434 429 486]
 [402 399 436 492 495]
 [497 436 448 419 422]]
Classification Report:
               precision    recall  f1-score   support

           0       0.22      0.21      0.22      2468
           1       0.20      0.19      0.19      2222
           2       0.20      0.20      0.20      2224
           3       0.21      0.22      0.22      2224
           4       0.18      0.19      0.19      2222

    accuracy                           0.20     11360
   macro avg       0.20      0.20      0.20     11360
weighted avg       0.20      0.20      0.20     11360